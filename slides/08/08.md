title: NPFL129, Lecture 8
class: title, cc-by-sa
style: .algorithm { background-color: #eee; padding: .5em }
# Correlation, Model Combination

## Jind≈ôich Libovick√Ω <small>(reusing materials by Milan Straka)</small>

### November 21, 2023

---
# Course Objectives: Where are we now?

After this course you should‚Ä¶

- Be able to reason about task/problems **suitable for ML**
   - Know when to use classification, regression and clustering
   - Be able to choose from this method Linear and Logistic Regression,
     Multilayer Perceptron, Nearest Neighbors, Naive Bayes, Gradient Boosted Decision
     Trees, $k$-means clustering

- Think about learning as (mostly probabilistic) **optimization on training data**
  - Know how the ML methods learn including theoretical explanation

- Know how to properly **evaluate** ML
  - Think about generalization (and avoiding overfitting)
  - Be able to choose a suitable evaluation metric
  - Responsibly decide what model is better

- Be able to **implement ML algorithms** on a conceptual level
- Be able to **use Scikit-learn** to solve ML problems in Python

---
class: middle
# Today's Lecture Objectives

After this lecture you should be able to

- Explain and implement different ways of measuring correlation: Pearson's
  correlation, Spearman's correlation, Kendall's $\tau$.

- Decide if correlation is a good metric for your model.

- Measure inter-annotator agreement and draw conclusions for data
  cleaning and for limits of your models.

- Use correlation with human judgment to validate evaluation metrics.

- Ensemble models with uncorrelated predictions.

- Distill ensembles into smaller models.

---
section: Covariance
# Covariance

Given a collection of random variables $‚Åáx_1, ‚Ä¶, ‚Åáx_N$, we know that
$$ùîº\left[‚àë\nolimits_i ‚Åáx_i\right] = ‚àë_i ùîº \big[‚Åáx_i\big].$$

~~~
But how about $\Var\big(‚àë_i ‚Åáx_i\big)$?

~~~
$\displaystyle \kern5em\Var\left(‚àë\nolimits_i ‚Åáx_i\right)
 = ùîº\left[\left(‚àë\nolimits_i ‚Åáx_i - ‚àë\nolimits_i ùîº[‚Åáx_i]\right)^2\right]$

~~~
$\displaystyle \phantom{\kern5em\Var\left(‚àë\nolimits_i ‚Åáx_i\right)}
 = ùîº\left[\left(‚àë\nolimits_i \big(‚Åáx_i - ùîº[‚Åáx_i]\big)\right)^2\right]$

~~~
$\displaystyle \phantom{\kern5em\Var\left(‚àë\nolimits_i ‚Åáx_i\right)}
 = ùîº\left[‚àë\nolimits_i ‚àë\nolimits_j \big(‚Åáx_i - ùîº[‚Åáx_i]\big) \big(‚Åáx_j - ùîº[‚Åáx_j]\big)\right]$

~~~
$\displaystyle \phantom{\kern5em\Var\left(‚àë\nolimits_i ‚Åáx_i\right)}
 = ‚àë_i ‚àë_j ùîº\left[\big(‚Åáx_i - ùîº[‚Åáx_i]\big) \big(‚Åáx_j - ùîº[‚Åáx_j]\big)\right].$

---
# Covariance

We define **covariance** of two random variables $‚Åáx, ‚Åáy$ as
$$\Cov(‚Åáx, ‚Åáy) = ùîº\Big[\big(‚Åáx - ùîº[‚Åáx]\big) \big(‚Åáy - ùîº[‚Åáy]\big)\Big].$$

~~~
Then,
$$\Var\left(‚àë\nolimits_i ‚Åáx_i\right) = ‚àë_i ‚àë_j \Cov(‚Åáx_i, ‚Åáx_j).$$

~~~
Note that $\Cov(‚Åáx, ‚Åáx) = \Var(‚Åáx)$ and that we can write covariance as
$$\begin{aligned}
  \Cov(‚Åáx, ‚Åáy)
   &= ùîº\Big[\big(‚Åáx - ùîº[‚Åáx]\big) \big(‚Åáy - ùîº[‚Åáy]\big)\Big] \\
   &= ùîº\big[‚Åáx ‚Åáy - ‚Åáx ùîº[‚Åáy] - ùîº[‚Åáx] ‚Åáy + ùîº[‚Åáx] ùîº[‚Åáy]\big] \\
   &= ùîº\big[‚Åáx ‚Åáy\big] - ùîº\big[‚Åáx\big] ùîº\big[‚Åáy\big].
\end{aligned}$$

---
section: Correlation
# Correlation

Two random variables $‚Åáx, ‚Åáy$ are **uncorrelated** if $\Cov(‚Åáx, ‚Åáy) = 0$;
otherwise, they are **correlated**.

~~~
Note that two _independent_ random variables are uncorrelated, because

$\displaystyle \kern10em\mathllap{\Cov(‚Åáx, ‚Åáy)} = ùîº\Big[\big(‚Åáx - ùîº[‚Åáx]\big) \big(‚Åáy - ùîº[‚Åáy]\big)\Big]$

~~~
$\displaystyle \kern10em{} = ‚àë_{x,y} P(x, y) \big(x - ùîº[x]\big) \big(y - ùîº[y]\big)$

~~~
$\displaystyle \kern10em{} = ‚àë_{x,y} P(x) \big(x - ùîº[x]\big) P(y) \big(y - ùîº[y]\big)$

~~~
$\displaystyle \kern10em{} = ‚àë_x P(x) \big(x - ùîº[x]\big) ‚àë_y P(y) \big(y - ùîº[y]\big)$

~~~
$\displaystyle \kern10em{} = ùîº_‚Åáx \big[‚Åáx - ùîº[‚Åáx]\big] ùîº_‚Åáy \big[‚Åáy - ùîº[‚Åáy]\big] = 0.$

~~~
However, dependent random variables can be uncorrelated ‚Äì random
uniform $‚Åáx$ on $[-1, 1]$ and $‚Åáy = |‚Åáx|$ are not independent ($‚Åáy$ is
completely determined by $‚Åáx$), but they are uncorrelated.

---
# Pearson correlation coefficient

There are several ways to measure correlation of random variables $‚Åáx, ‚Åáy$.

**Pearson correlation coefficient**, denoted as $œÅ$ or $r$, is defined as
$$\begin{aligned}
  œÅ &‚âù \frac{\Cov(‚Åáx, ‚Åáy)}{\sqrt{\Var(‚Åáx)} \sqrt{\Var(‚Åáy)}} \\
  r &‚âù \frac{‚àë_i (x_i - xÃÑ) (y_i - yÃÑ)}{\sqrt{‚àë_i (x_i - xÃÑ)^2} \sqrt{‚àë_i (y_i - yÃÑ)^2}},
\end{aligned}$$
where:
~~~
- $œÅ$ is used when the full expectation is computed (population Pearson
  correlation coefficient);
~~~
- $r$ is used when estimating the coefficient from data (sample Pearson
  correlation coefficient);
  - $xÃÑ$ and $yÃÑ$ are sample estimates of the respective means.

---
class: dbend
# Pearson correlation coefficient

The value of Pearson correlation coefficient is in fact normalized covariance,
because its value is always bounded by $-1 ‚â§ œÅ ‚â§ 1$ (and the same holds for $r$).

~~~
The bound can be derived from

$\displaystyle \kern5em\mathllap{0} ‚â§ ùîº\bigg[\bigg(\frac{(‚Åáx - ùîº[‚Åáx])}{\sqrt{\Var(‚Åáx)}} - œÅ\frac{(‚Åáy - ùîº[‚Åáy])}{\sqrt{\Var(‚Åáy)}}\bigg)^2\bigg]$

~~~
$\displaystyle \kern5em{} = ùîº\bigg[\frac{(‚Åáx - ùîº[‚Åáx])^2}{\Var(‚Åáx)}\bigg]
                            - 2œÅùîº\bigg[\frac{(‚Åáx - ùîº[‚Åáx])}{\sqrt{\Var(‚Åáx)}}\frac{(‚Åáy - ùîº[‚Åáy])}{\sqrt{\Var(‚Åáy)}}\bigg]
                            + œÅ^2 ùîº\bigg[\frac{(‚Åáy - ùîº[‚Åáy])^2}{\Var(‚Åáy)}\bigg]$

~~~
$\displaystyle \kern5em{} = \frac{\Var(‚Åáx)}{\Var(‚Åáx)} - 2œÅ‚ãÖœÅ + œÅ^2 \frac{\Var(‚Åáy)}{\Var(‚Åáy)} = 1 - œÅ^2,$

~~~
which yields $œÅ^2 ‚â§ 1$.

---
# Pearson correlation coefficient

Pearson correlation coefficient quantifies **linear dependence** of the two
random variables.

![w=84%,h=center](correlation_coefficient.png)

---
# Pearson correlation coefficient

Pearson correlation coefficient quantifies **linear dependence** of the two
random variables.

![w=100%,h=center](correlation_examples.svgz)

---
# Pearson correlation coefficient

The four displayed variables have the same mean 7.5, variance 4.12,
Pearson correlation coefficient 0.816 and regression line $3 + \frac{1}{2}x$.

![w=60%,h=center](ancombes_quartet.svgz)

---
# Nonlinear Correlation ‚Äì Spearman's $œÅ$

To measure also nonlinear correlation, two coefficients are commonly used.

### Spearman's rank correlation coefficient $œÅ$
Spearman's $œÅ$ is Pearson correlation coefficient measured on **ranks** of the
original data, where a rank of an element is its index in sorted ascending
order.

![w=100%](spearman.svgz)

---
# Nonlinear Correlation ‚Äì Kendall's $œÑ$

### Kendall rank correlation coefficient $œÑ$
Kendall's $œÑ$ measures the amount of _concordant pairs_ (pairs where $y$
increases/decreases when $x$ does), minus the _discordant pairs_
(where $y$ increases/decreases when $x$ does the opposite):

$$\begin{aligned}
  œÑ &‚âù \frac{|\{\mathrm{pairs}~i ‚â† j: x_j > x_i, y_j > y_i\}| - |\{\mathrm{pairs}~i ‚â† j: x_j > x_i, y_j < y_i\}|}{\binom{n}{2}} \\
    &= \frac{‚àë_{i < j} \sign(x_j - x_i) \sign(y_j - y_i)}{\binom{n}{2}}.
\end{aligned}$$

~~~
There is no clear consensus whether to use Spearman's $œÅ$ or Kendall's $œÑ$.
When there are no/few ties in the data, Kendall's $œÑ$ offers two minor
advantages ‚Äì $\frac{1+œÑ}{2}$ can be interpreted as a probability of
a concordant pair, and Kendall's $œÑ$ converges to a normal distribution faster.

~~~
As defined, the range of Kendall's $œÑ ‚àà [-1, 1]$. However, if there are ties,
its range is smaller ‚Äì therefore, several corrections (not discussed here) exist
to adjust its value in case of ties.

---
class: middle
# Correlation is not causation

![w=90%,mw=40%,h=left](correlation_meme.png)![w=50%](correlation_xkcd.png)

---
section: CorrelationUsed
# Use of Correlation in Machine Learning

In ML, correlation is commonly used as

- Evaluation metric for some tasks;

- Measuring data annotation quality;

- Assessing the quality of automatic metrics by comparing it to human judgment.

---
# Correlation as evaluation metric

- Learning to rank (e.g., document retrieval): we do not care about the actual values

   - Kendall's $\tau$, Spearman's correlation

   - When there want correct items rank before incorrect items: precision
     (assuming fixed tok-$k$, typically at 5, 10), recall (often ill-defined),
     mean reciprocal rank

   $$\operatorname{MRR} = \frac{1}{N}\sum_{i=1}^{N}\frac{1}{\text{rank of the first relevant item}}$$
~~~
- Evaluating pair similarity: word embeddings, sentence embeddings

   - Similarity estimates from psycholinguistic experiments: scores for word/sentence pairs

   - Measure Pearson/Spearman correlation between embedding distances and similarity scores

---
# Inter-annotator agreement (1)

![w=35%,f=right](iaa_meme.png)

- Inter-annotator agreement can tell us

   - How well defined the task is

   - How reliable annotators/user ratings are

   - What data items are suspicious / difficult

<br>
~~~

- For continuous target values: Pearson's/Spearman's correlation

~~~

- For classification tasks: Cohen's $\kappa$ \
    $p_O$ is observed agreement, $p_E$ expected agreement by chance

$$\kappa = \frac{p_O - p_E}{1 - p_E}$$

---
# Inter-annotator agreement (2)

- Can be used to filter out confusing data points and unreliable annotators

- Not all outliers are noise! Low IAA can reveal cultural differences.

<br>
<br>

~~~
IAA sets natural upper boundary for ML performance. Performance over IAA is
suspicious!

<br>

![w=60%,h=center](baseline_to_agreement.svgz)

~~~
* Trivial baseline for classification: majority class, for regression average,
  or something based on simple rules

* Performance over IAA is more likely overfitting for the way the data is
  curated than super-human performance.

---
# Correlation with human judgment

For some tasks, it might not be clear how to measure the model performance:

**Grammar checking**: the $\beta$ parameter
![w=24%,h=center](correlation_metrics.svgz)

~~~

**Machine translation**: evaluation is subjective by definition, we design
metrics to correlate with human judgment.

- SoTA machine translation metrics are typically machine-learned.

- Different metrics might be suitable different tiers of translation quality.

- There is an annual competition in MT quality and MT metric quality.

---
section: Model Combination
# Model Combination aka Ensembling

The goal of **ensembling** is to combine several models in order to reach
higher performance.

~~~
The simplest approach is to train several independent models and then to combine
their predictions by averaging or voting.

~~~
The terminology varies, but for classification:
- voting (or hard voting) usually means predicting the class predicted most
  often by the individual models,
~~~
- averaging (or soft voting) denotes averaging the returned model distributions
  and predicting the class with the highest probability.

~~~
The main idea behind ensembling is that if models have uncorrelated
errors, then by averaging model predictions the errors will cancel out.

---
# Visualization of Ensembling Performance

Consider ensembling predictions generated uniformly on a planar disc:
![w=100%](ensemble_visualization-r1.svgz)
~~~
![w=100%](ensemble_visualization-r1b.svgz)
~~~
![w=100%](ensemble_visualization-r42.svgz)

---
# Model Combination aka Ensembling

If we denote the prediction of a model $y_i$ on a training example $(‚Üíx, t)$ as
$y_i(‚Üíx) = t + Œµ_i(‚Üíx)$, so that $Œµ_i(‚Üíx)$ is the model error on example $‚Üíx$,
the mean square error of the model is
$$ùîº\big[(y_i(‚Üíx) - t)^2\big] = ùîº\big[Œµ_i^2(‚Üíx)\big].$$

~~~
Considering $M$ models, we analogously get that the mean square error
of the ensemble is
$$ùîº\bigg[\Big(\frac{1}{M} ‚àë\nolimits_i Œµ_i(‚Üíx)\Big)^2\bigg].$$

~~~
Finally, assuming that the individual errors $Œµ_i$ have zero mean and are _uncorrelated_,
we get that $ùîº\big[Œµ_i(‚Üíx) Œµ_j(‚Üíx)\big] = 0$ for $i ‚â† j$, and therefore,
~~~
$$ùîº\Big[\Big(\frac{1}{M} ‚àë\nolimits_i Œµ_i(‚Üíx)\Big)^2\Big]
= ùîº\Big[\frac{1}{M^2} ‚àë\nolimits_{i,j} Œµ_i(‚Üíx) Œµ_j(‚Üíx)\Big]
= \frac{1}{M} ùîº\Big[\frac{1}{M} ‚àë\nolimits_i Œµ_i^2(‚Üíx)\Big],$$
~~~
so the average error of the ensemble is $\frac{1}{M}$ times the average error
of the individual models.

---
# Bagging ‚Äì Bootstrap Aggregation

For neural network models, training models with independent random initialization is
usually enough, given that the loss has many local minima, so the models tend to
be quite independent just when using different random initialization.

~~~
However, algorithms with convex loss functions usually converge to the same
optimum independent of randomization.

~~~
In these cases, we can use **bagging**, which stands for **bootstrap
aggregation**.

~~~
![w=50%,f=right](bagging.svgz)

In bagging, we construct a different dataset for every model we train.
We construct it using **bootstrapping** ‚Äì we sample as many training instances
as the original dataset has, but **with replacement**.

Such dataset is sampled using the same empirical data distribution and has the
same size, but is not identical.

---
# Knowledge Distillation

- Model ensemble might be too slow or too big to use.

~~~

- Knowledge distillation = training a **student** model that mimics behaviour
  of a **teacher model** (a bigger on or model ensemble).

~~~

**Algorithm:**

1. Process training data (or additional unlabelled data) with the best current
   model and get the output distribution $p_\text{teacher}(\boldsymbol y |
   \boldsymbol x; \boldsymbol w )$ (sometimes called _pseudolikelihood_)

2. Train a model with $H\left(p_\text{student}(\boldsymbol y | \boldsymbol x;
   \boldsymbol w), p_\text{teacher}(\boldsymbol y | \boldsymbol x; \boldsymbol
   w )\right)$ as a training objective.

~~~
**Intuition:** Complete distribution provides stronger supervision that just
one-hot target, so it is easier for the smaller model to learn from such
synthetic data.

~~~
<br>

<small>Historical note: Term knowledge distillation come from a 2015 by
Geoffrey Hinton et al., before a similar approach was called model
compression.</small>


---
class: middle
# Today's Lecture Objectives

After this lecture you should be able to

- Explain and implement different ways of measuring correlation: Pearson's
  correlation, Spearman's correlation, Kendall's $\tau$

- Decide if correlation is a good metric for your model

- Measure inter-annotator agreement and draw conclusions for data cleaning and
  for limits of your models

- Use correlation with human judgment to validate evaluation metrics

- Ensemble models with uncorrelated predictions

- Distill ensembles into smaller models.

